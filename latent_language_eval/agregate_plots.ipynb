{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import plot_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_lang = 'zh'\n",
    "target_lang = 'fr'\n",
    "model_size = '7b'\n",
    "out_dir = './visuals'\n",
    "save_dir = '../eval_resuslts/logit_lens/summaries/'\n",
    "save_plots = True\n",
    "save_format = \".png\"\n",
    "# save_format = \".pdf\"\n",
    "# target_task = \"translation\"\n",
    "target_task = \"cloze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = []\n",
    "outputs = []\n",
    "\n",
    "langs_infix = f\"{input_lang}_{target_lang}\" if target_task == \"translation\" else f\"{target_lang}\"\n",
    "\n",
    "def load_latents(model_label):\n",
    "    return [torch.load(f'{os.path.join(out_dir, model_label)}/{target_task}/{model_label}_{langs_infix}_latent_probs.pt')]\n",
    "\n",
    "def load_outputs(model_label):\n",
    "    return [torch.load(f'{os.path.join(out_dir, model_label)}/{target_task}/{model_label}_{langs_infix}_out_probs.pt')]\n",
    "\n",
    "\n",
    "source_labels = [\n",
    "    \"hf_16bit\",\n",
    "    \"bnb_4bit\",\n",
    "    \"rtn_4bit\",\n",
    "    \"awq_4bit\",\n",
    "    \"gptq_4bit\",\n",
    "    # \"twq_4bit_combined\",\n",
    "    # \"twq_4bit_random\",\n",
    "    # \"mpq_4bit_combined\",\n",
    "    # \"mpq_4bit_random\",\n",
    "    # \"mpqr_4bit_combined\",\n",
    "    # \"mpqr_4bit_random\",\n",
    "]\n",
    "\n",
    "for label in source_labels:\n",
    "    latents += load_latents(label)\n",
    "    outputs += load_outputs(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size2tik = {\"tiny\" : 5, '7b': 5, '13b': 5, '70b': 10}\n",
    "\n",
    "\n",
    "def plot_custom(ax, output, label, color='black', delta=0, confidence=False, marker=None, do_lines=False, offset=0, line_alpha=1):\n",
    "    plot_ci(ax, (output-delta)[:,offset:], label, color, do_lines=do_lines, plt_params={\"linewidth\":1, \"marker\":marker, \"alpha\":line_alpha}, do_confidence=confidence, layer_idx_offset=offset, confidence_alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_base = [\n",
    "    \"base\",\n",
    "    \"bnb 4bit\",\n",
    "    \"rtn 4bit\",\n",
    "    \"awq 4bit\",\n",
    "    \"gptq 4bit\",\n",
    "    # \"twq 4bit\\n(lang. neurons)\"\n",
    "    # \"twq 4bit\\n(random)\"\n",
    "    # \"mpq 4bit\\n(lang. neurons)\"\n",
    "    # \"mpq 4bit\\n(random)\"\n",
    "    # \"mpqr 4bit\\n(lang. neurons)\"\n",
    "    # \"mpqr 4bit\\n(random)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "plt.axhline(y=0, color='grey', linestyle='--', linewidth=0.7, label=\"baseline\")\n",
    "\n",
    "lang = target_lang\n",
    "\n",
    "offset = 17\n",
    "delta = outputs[0]\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "cmap = plt.get_cmap('turbo')\n",
    "colors = [cmap(i / (len(outputs) - 1)) for i in range(len(outputs))]\n",
    "markers = [\"*\"] + [\"o\"]*(len(outputs)-1)\n",
    "for n in range(1, len(outputs)):\n",
    "    plot_custom(ax2, outputs[n], labels[n], color=colors[n], marker=markers[n] ,delta=delta, offset=offset)\n",
    "\n",
    "\n",
    "ax2.set_xlabel('layer')\n",
    "ax2.set_ylabel('probability delta')\n",
    "if model_size == '7b' or \"tiny\":\n",
    "    ax2.set_xlim(offset, outputs[0].shape[1]+1)\n",
    "else:\n",
    "    ax2.set_xlim(offset, round(outputs[0].shape[1]/10)*10+1)\n",
    "\n",
    "ax2.set_ylim(-0.35, 0.1)\n",
    "# ax2.set_yscale('log')\n",
    "\n",
    "# put legend on the top left\n",
    "ax2.set_title(f\"Probability delta of the [{lang}] token response\")\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "if save_plots:\n",
    "    os.makedirs(f'{save_dir}/{target_task}/{langs_infix}', exist_ok=True)\n",
    "    plt.savefig(f'{save_dir}/{target_task}/{langs_infix}/{model_size}_{langs_infix}_probas_ent_tgt_delta{save_format}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "lang = target_lang\n",
    "\n",
    "offset = 17\n",
    "delta = 0\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "cmap = plt.get_cmap('turbo')\n",
    "colors = [cmap(i / (len(outputs) - 1)) for i in range(len(outputs))]\n",
    "markers = [\"*\"] + [\"o\"]*(len(outputs)-1)\n",
    "for n in range(0, len(outputs)):\n",
    "    plot_custom(ax2, outputs[n], labels[n], color=colors[n], marker=markers[n] ,delta=delta, offset=offset)\n",
    "\n",
    "\n",
    "ax2.set_xlabel('layer')\n",
    "ax2.set_ylabel('probability')\n",
    "if model_size == '7b' or \"tiny\":\n",
    "    ax2.set_xlim(offset, outputs[0].shape[1]+1)\n",
    "else:\n",
    "    ax2.set_xlim(offset, round(outputs[0].shape[1]/10)*10+1)\n",
    "\n",
    "ax2.set_ylim(0, 0.8)\n",
    "\n",
    "\n",
    "ax2.set_title(f\"Probability of the [{lang}] token response\")\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "if save_plots:\n",
    "    os.makedirs(f'{save_dir}/{target_task}/{langs_infix}', exist_ok=True)\n",
    "    plt.savefig(f'{save_dir}/{target_task}/{langs_infix}/{model_size}_{langs_infix}_probas_ent_tgt{save_format}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "lang = \"en\"\n",
    "\n",
    "offset = 15\n",
    "delta = 0#latents[0]\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "cmap = plt.get_cmap('turbo')\n",
    "colors = [cmap(i / (len(outputs) - 1)) for i in range(len(outputs))]\n",
    "markers = [\"*\"] + [\"o\"]*(len(outputs)-1)\n",
    "for n in range(0, len(latents)):\n",
    "    plot_custom(ax2, latents[n], labels[n], color=colors[n], marker=markers[n] ,delta=delta, offset=offset)\n",
    "\n",
    "\n",
    "ax2.set_xlabel('layer')\n",
    "ax2.set_ylabel('probability')\n",
    "if model_size == '7b' or \"tiny\":\n",
    "    ax2.set_xlim(offset, latents[0].shape[1]+1)\n",
    "else:\n",
    "    ax2.set_xlim(offset, round(latents[0].shape[1]/10)*10+1)\n",
    "\n",
    "ax2.set_title(f\"Probability of the [{lang}] token response\")\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "if save_plots:\n",
    "    os.makedirs(f'{save_dir}/{target_task}/{langs_infix}', exist_ok=True)\n",
    "    plt.savefig(f'{save_dir}/{target_task}/{langs_infix}/{model_size}_{langs_infix}_probas_ent_src{save_format}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "plt.axhline(y=0, color='grey', linestyle='--', linewidth=0.7, label=\"baseline\")\n",
    "\n",
    "lang = \"en\"\n",
    "\n",
    "offset = 15\n",
    "delta = latents[0]\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "cmap = plt.get_cmap('turbo')\n",
    "colors = [cmap(i / (len(outputs) - 1)) for i in range(len(outputs))]\n",
    "markers = [\"*\"] + [\"o\"]*(len(outputs)-1)\n",
    "for n in range(1, len(outputs)):\n",
    "    plot_custom(ax2, latents[n], labels[n], color=colors[n], marker=markers[n] ,delta=delta, offset=offset)\n",
    "\n",
    "\n",
    "ax2.set_xlabel('layer')\n",
    "ax2.set_ylabel('probability delta')\n",
    "if model_size == '7b' or \"tiny\":\n",
    "    ax2.set_xlim(offset, latents[0].shape[1]+1)\n",
    "else:\n",
    "    ax2.set_xlim(offset, round(latents[0].shape[1]/10)*10+1)\n",
    "\n",
    "ax2.set_title(f\"Probability delta of the [{lang}] token response\")\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "if save_plots:\n",
    "    os.makedirs(f'{save_dir}/{target_task}/{langs_infix}', exist_ok=True)\n",
    "    plt.savefig(f'{save_dir}/{target_task}/{langs_infix}/{model_size}_{langs_infix}_probas_ent_src_delta{save_format}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "\n",
    "offset = 17\n",
    "delta = 0#latents[0]\n",
    "\n",
    "selected_indeces = range(len(outputs))\n",
    "idx_end = len(selected_indeces)\n",
    "\n",
    "cmap = plt.get_cmap('turbo')\n",
    "colors = [cmap(i / (idx_end*2 - 1)) for i in range(idx_end*2+1)]\n",
    "colors[idx_end] = colors[0]\n",
    "\n",
    "lang = \"en\"\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "markers = [\"*\"] + [\"s\"]*len(latents)\n",
    "for n, m in zip(selected_indeces, range(idx_end)):\n",
    "    plot_custom(ax2, latents[n], labels[n], color=colors[:idx_end][m], marker=markers[n] ,delta=delta, offset=offset, confidence=True)\n",
    "\n",
    "\n",
    "lang = target_lang\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "markers = [\"*\"] + [\"o\"]*len(latents)\n",
    "\n",
    "for n, m in zip(selected_indeces, range(idx_end)):\n",
    "    plot_custom(ax2, outputs[n], labels[n], color=colors[idx_end:][m], marker=markers[n] ,delta=delta, offset=offset, confidence=True)\n",
    "\n",
    "ax2.set_xlabel('layer')\n",
    "ax2.set_ylabel('probability')\n",
    "if model_size == '7b' or \"tiny\":\n",
    "    ax2.set_xlim(offset, latents[0].shape[1]+1)\n",
    "else:\n",
    "    ax2.set_xlim(offset, round(latents[0].shape[1]/10)*10+1)\n",
    "\n",
    "ax2.set_title(f\"Probability of token responses in [{target_lang}] and [en]\")\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "if save_plots:\n",
    "    os.makedirs(f'{save_dir}/{target_task}/{langs_infix}', exist_ok=True)\n",
    "    plt.savefig(f'{save_dir}/{target_task}/{langs_infix}/{model_size}_{langs_infix}_probas_ent_comp{save_format}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "plt.axhline(y=0, color='grey', linestyle='--', linewidth=0.7, label=\"baseline\")\n",
    "\n",
    "offset = 17\n",
    "delta = latents[0]\n",
    "\n",
    "selected_indeces = range(len(outputs))\n",
    "idx_end = len(selected_indeces)\n",
    "\n",
    "cmap = plt.get_cmap('turbo')\n",
    "colors = [cmap(i / (idx_end*2 - 1)) for i in range(idx_end*2+1)]\n",
    "# colors[idx_end] = colors[0]\n",
    "\n",
    "lang = \"en\"\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "markers = [\"*\"] + [\"s\"]*len(latents)\n",
    "for n, m in zip(selected_indeces, range(idx_end)):\n",
    "    plot_custom(ax2, latents[n], labels[n], color=colors[:idx_end][m], marker=markers[n] ,delta=delta, offset=offset, confidence=True)\n",
    "\n",
    "delta = outputs[0]\n",
    "\n",
    "lang = target_lang\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "markers = [\"*\"] + [\"o\"]*len(latents)\n",
    "\n",
    "for n, m in zip(selected_indeces, range(idx_end)):\n",
    "    plot_custom(ax2, outputs[n], labels[n], color=colors[idx_end:][m], marker=markers[n] ,delta=delta, offset=offset, confidence=True)\n",
    "\n",
    "ax2.set_xlabel('layer')\n",
    "ax2.set_ylabel('probability delta')\n",
    "if model_size == '7b' or \"tiny\":\n",
    "    ax2.set_xlim(offset, latents[0].shape[1]+1)\n",
    "else:\n",
    "    ax2.set_xlim(offset, round(latents[0].shape[1]/10)*10+1)\n",
    "\n",
    "ax2.set_title(f\"Probability delta of token responses in [{target_lang}] and [en]\")\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "if save_plots:\n",
    "    os.makedirs(f'{save_dir}/{target_task}/{langs_infix}', exist_ok=True)\n",
    "    plt.savefig(f'{save_dir}/{target_task}/{langs_infix}/{model_size}_{langs_infix}_probas_ent_comp_deltas{save_format}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "plt.axhline(y=0, color='grey', linestyle='--', linewidth=0.7, label=\"baseline\")\n",
    "\n",
    "offset = 17\n",
    "delta = latents[0]\n",
    "\n",
    "selected_indeces = range(len(outputs))\n",
    "idx_end = len(selected_indeces)\n",
    "\n",
    "cmap = plt.get_cmap('turbo')\n",
    "colors = [cmap(i / (idx_end*2 - 1)) for i in range(idx_end*2+1)]\n",
    "colors[idx_end] = colors[0]\n",
    "\n",
    "lang = \"en\"\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "markers = [\"*\"] + [\"s\"]*len(latents)\n",
    "for n, m in zip(selected_indeces, range(idx_end)):\n",
    "    plot_custom(ax2, latents[n], labels[n], color=colors[:idx_end][m], marker=markers[n] ,delta=delta, offset=offset, confidence=True)\n",
    "\n",
    "delta = outputs[0]\n",
    "\n",
    "lang = target_lang\n",
    "labels = [lang + \" \" + lab for lab in label_base]\n",
    "markers = [\"*\"] + [\"o\"]*len(latents)\n",
    "\n",
    "for n, m in zip(selected_indeces, range(idx_end)):\n",
    "    plot_custom(ax2, outputs[n], labels[n], color=colors[idx_end:][m], marker=markers[n] ,delta=delta, offset=offset, confidence=True)\n",
    "\n",
    "ax2.set_xlabel('layer')\n",
    "ax2.set_ylabel('probability delta')\n",
    "if model_size == '7b' or \"tiny\":\n",
    "    ax2.set_xlim(offset, latents[0].shape[1]+1)\n",
    "else:\n",
    "    ax2.set_xlim(offset, round(latents[0].shape[1]/10)*10+1)\n",
    "\n",
    "ax2.set_title(f\"Normalized probability delta of token responses\\nwhen translating from [{input_lang}] to [{target_lang}], in [{target_lang}] and [en]\")\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "if save_plots:\n",
    "    os.makedirs(f'{save_dir}/{target_task}/{langs_infix}', exist_ok=True)\n",
    "    plt.savefig(f'{save_dir}/{target_task}/{langs_infix}/{model_size}_{langs_infix}_probas_ent_comp_deltas{save_format}', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "lang = \"\"\n",
    "\n",
    "plt.axhline(y=0, color='grey', linestyle='--', linewidth=0.7)\n",
    "\n",
    "offset = 15\n",
    "delta = 0#outputs[0]\n",
    "labels = label_base\n",
    "cmap = plt.get_cmap('turbo')\n",
    "colors = [cmap(i / (len(outputs) - 1)) for i in range(len(outputs))]\n",
    "markers = [\"*\"] + [\"o\"]*(len(outputs)-1)\n",
    "for n in range(0, len(outputs)):\n",
    "    plot_custom(ax2, outputs[n], labels[n], color=colors[n], marker=markers[n] ,delta=latents[n], offset=offset, line_alpha=0.7)\n",
    "\n",
    "\n",
    "ax2.set_xlabel('layer')\n",
    "ax2.set_ylabel('probability delta')\n",
    "if model_size == '7b' or \"tiny\":\n",
    "    ax2.set_xlim(offset, outputs[0].shape[1]+1)\n",
    "else:\n",
    "    ax2.set_xlim(offset, round(outputs[0].shape[1]/10)*10+1)\n",
    "\n",
    "ax2.set_title(f\"Probability difference between [{target_lang}] and [en] token responses (bigger is better)\")\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "if save_plots:\n",
    "    os.makedirs(f'{save_dir}/{target_task}/{langs_infix}', exist_ok=True)\n",
    "    plt.savefig(f'{save_dir}/{target_task}/{langs_infix}/{model_size}_{langs_infix}_probas_compare{save_format}', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
